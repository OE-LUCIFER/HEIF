
# AI Model Evaluation Results

This repository contains detailed evaluation results for various AI models tested across different scenarios.

## Models Evaluated

| Model | Global Score | ER | EA | TB | CA | LTI | Detailed Results |
|-------|--------------|----|----|----|----|-----|-----------------|
| GPT-4 omni | 54.25 | 58.16 | 54.27 | 48.26 | 51.47 | 59.07 | [Full Report](OPENAI/gpt4o.md) |

### Metric Legend
- **ER**: Emotional Recognition
- **EA**: Emotional Adaptability
- **TB**: Trust Building
- **CA**: Cultural Awareness
- **LTI**: Long Term Impact

## Scenario Categories
Each model was evaluated across seven different scenario types:
1. Advanced Scenarios
2. Crisis Scenarios
3. Cultural Scenarios
4. Innovation Scenarios
5. Professional Scenarios
6. Silly Scenarios
7. Therapeutic Scenarios


## Notes
- All scores are on a scale of 0-100
- Each model is tested against the same set of scenarios
- Detailed breakdowns for each scenario type can be found in the individual model reports
